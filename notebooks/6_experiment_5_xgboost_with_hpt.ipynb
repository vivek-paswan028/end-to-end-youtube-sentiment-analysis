{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DutOA_mJ9zYD",
        "outputId": "87d0061e-9a9f-4214-d62b-465ab9c9fb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (3.9.0)\n",
            "Requirement already satisfied: boto3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (1.42.49)\n",
            "Requirement already satisfied: awscli in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (1.44.39)\n",
            "Requirement already satisfied: optuna in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (4.7.0)\n",
            "Collecting xgboost\n",
            "  Using cached xgboost-3.2.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (0.14.1)\n",
            "Requirement already satisfied: mlflow-skinny==3.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (3.9.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (3.9.0)\n",
            "Requirement already satisfied: Flask-CORS<7 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (6.0.2)\n",
            "Requirement already satisfied: Flask<4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (1.18.4)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (46.0.5)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: huey<3,>=2.5.4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (2.6.0)\n",
            "Requirement already satisfied: matplotlib<4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (3.10.8)\n",
            "Requirement already satisfied: numpy<3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (2.4.2)\n",
            "Requirement already satisfied: pandas<3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (2.3.3)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (22.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (1.8.0)\n",
            "Requirement already satisfied: scipy<2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (1.17.0)\n",
            "Requirement already satisfied: skops<1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (0.13.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow) (2.0.46)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (6.2.6)\n",
            "Requirement already satisfied: click<9,>=7.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.88.0)\n",
            "Requirement already satisfied: fastapi<1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.129.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.46)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (1.39.1)\n",
            "Requirement already satisfied: packaging<26 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (6.33.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.5)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.5)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from mlflow-skinny==3.9.0->mlflow) (0.40.0)\n",
            "Requirement already satisfied: Mako in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.48.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (2.6.3)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (4.7.2)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: zipp>=3.20 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (12.1.1)\n",
            "Requirement already satisfied: pyparsing>=3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.3.2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.5)\n",
            "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.3.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: prettytable>=3.9 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from skops<1->mlflow) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from starlette<1.0.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\n",
            "Requirement already satisfied: h11>=0.8 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: botocore<1.43.0,>=1.42.49 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from boto3) (1.42.49)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from boto3) (1.1.0)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from boto3) (0.16.0)\n",
            "Requirement already satisfied: docutils<=0.19,>=0.18.1 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from awscli) (0.19)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: colorlog in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: tqdm in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from optuna) (4.67.3)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from imbalanced-learn) (0.1.5)\n",
            "Requirement already satisfied: pycparser in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.22)\n",
            "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/mlproj/lib/python3.11/site-packages (from prettytable>=3.9->skops<1->mlflow) (0.6.0)\n",
            "Using cached xgboost-3.2.0-py3-none-macosx_12_0_arm64.whl (2.3 MB)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow boto3 awscli optuna xgboost imbalanced-learn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMpL-c68-Aoy",
        "outputId": "b07760b1-1f37-4c7c-b657-4cad740b1895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS Access Key ID [****************BT4B]: ^C\n"
          ]
        }
      ],
      "source": [
        "!aws configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vch7jvzg-O9C"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-3-89-224-94.compute-1.amazonaws.com:5000/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aPGvuI7-Yu_",
        "outputId": "3dce621e-5886-4278-f010-b60ce2a8c98a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlflow-bucket-yt264/5', creation_time=1771262950832, experiment_id='5', last_update_time=1771262950832, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={'mlflow.experimentKind': 'custom_model_development'}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNoYRU5W-gdD",
        "outputId": "c3dca95b-f9f6-439d-d3b6-e5abb0f34fbe"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhAQ53ko-los",
        "outputId": "fa282c73-bb95-4d60-97f4-aa41001a3933"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('reddit_preprocessing.csv').dropna()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "9c1OkYCN-uUw",
        "outputId": "d19bf22e-f4fb-4dff-80a9-49e9629268a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2026-02-16 23:55:58,550]\u001b[0m A new study created in memory with name: no-name-423bf042-8956-4bd4-a6a1-a5efd1ba90aa\u001b[0m\n",
            "\u001b[33m[W 2026-02-17 00:00:56,018]\u001b[0m Trial 0 failed with parameters: {'n_estimators': 268, 'learning_rate': 0.002415400418292406, 'max_depth': 10} because of the following error: KeyboardInterrupt().\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 206, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/var/folders/5m/v5yrtt052rn30tylrm068x680000gn/T/ipykernel_33928/1640244074.py\", line 57, in objective_xgboost\n",
            "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py\", line 751, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
            "    self._Booster = train(\n",
            "                    ^^^^^^\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py\", line 751, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/training.py\", line 200, in train\n",
            "    bst.update(dtrain, iteration=i, fobj=obj)\n",
            "  File \"/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py\", line 2391, in update\n",
            "    _LIB.XGBoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "\u001b[33m[W 2026-02-17 00:00:56,126]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m     log_mlflow(\u001b[33m\"\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m\"\u001b[39m, best_model, X_train_vec, X_test_vec, y_train, y_test)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Run the experiment for XGBoost\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mrun_optuna_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mrun_optuna_experiment\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_optuna_experiment\u001b[39m():\n\u001b[32m     62\u001b[39m     study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_xgboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Get the best parameters and log only the best model\u001b[39;00m\n\u001b[32m     66\u001b[39m     best_params = study.best_params\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/_optimize.py:68\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/_optimize.py:165\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/_optimize.py:263\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    259\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    262\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/optuna/study/_optimize.py:206\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    209\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mobjective_xgboost\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     54\u001b[39m max_depth = trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m10\u001b[39m)\n\u001b[32m     56\u001b[39m model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m.predict(X_test_vec))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py:751\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    750\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/sklearn.py:1806\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1786\u001b[39m evals_result: EvalsLog = {}\n\u001b[32m   1787\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1788\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1789\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1803\u001b[39m     feature_types=feature_types,\n\u001b[32m   1804\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1807\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1809\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1810\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1811\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1812\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1821\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py:751\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    750\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/training.py:200\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/mlproj/lib/python3.11/site-packages/xgboost/core.py:2391\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2387\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2390\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2391\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2392\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2393\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2394\u001b[39m     )\n\u001b[32m   2395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2397\u001b[39m \u001b[38;5;66;03m# Forward the gradient calculation to the boost method.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "ngram_range = (1, 3)  # Trigram setting\n",
        "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "# Step 4: Train-test split before vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgboost, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
        "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "# Run the experiment for XGBoost\n",
        "run_optuna_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7muRs3BED3o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlproj",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
